# -*- coding: utf-8 -*-
"""K-Nearest Neighbor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nuTdRfJ2fsaDyrld-3ZB28uO0fmaII55

# DataSet

Menginisialisasi Library
"""

import numpy as np
import matplotlib.pyplot as plt 
import pandas as pd
import seaborn as sns
import parser
from math import sqrt
from pandas.plotting import scatter_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn import metrics
import pandas.util.testing as tm
print('Selesai')

"""Memanggil Data"""

url ='https://query.data.world/s/s4t2rolqb72wcnbhklkwvqo2g7sfi5'
features = ['Age', 'Sex', 'Cp', 'Trestbps', 'Chol', 'Fbs', 'Restecg', 'Thalach', 'Exang', 
            'Oldpeak', 'Slope', 'Ca', 'Thal','Num']
data = pd.read_excel(url,names=features, encoding= 'unicode_escape')
data.head()

"""Deskripsi Data"""

data.describe()

"""PREPROCESING MISSING VALUE

Sebelum di proses
"""

###Memilih kolom data yang ada missing valuenya
X=data.iloc[:,11].values #Menunjukkan kolom dengan index 11 atau kolom Ca
Y=data.iloc[:,12].values #Menunjukkan kolom dengan index 12 atau kolom Thal
print ("data Ca : \n",X)
print("data Thal : \n",Y)

"""menampilkan grafik dari missing value"""

#Menampilkan gambar letak missing value
sns.heatmap(data.isnull(),cbar=False)
plt.title('Heatmap Missing Value')
plt.show()

"""Menampilkan Percentase missing value"""

#Menampilkan Persentase dari Missing value tersebut
(data.isnull().sum()/len(data)).to_frame('persentase missing')

"""Menampilkan replace data"""

#Menampilkan Mising Value pada Kolom Ca dan Thal
#dan 
#Menampilkan Hasil Nilai Median
data['Ca_imputed_median'] = data['Ca'].replace(np.nan, data.Ca.median())
a=data[['Ca','Ca_imputed_median']].head(274)
data['Thal_imputed_median'] = data['Thal'].replace(np.nan, data.Thal.median())
b=data[['Thal','Thal_imputed_median']].head(84)
print("Replace data Ca: ",a)
print("Replace data Thal: \n",b)

#Mengganti Missing Value dengan Nilai Median yang didapatkan
median = data["Ca"].median()
data["Ca"] = data["Ca"].replace(np.nan, median)
median = data["Thal"].median()
data["Thal"] = data["Thal"].replace(np.nan, median)
ca=data.Ca.head(274)
thal=data.Thal.head(83)
print("Hasil replace data Ca: \n",ca)
print("Hasil replace data Thal: \n",thal)

"""Pembuktian data telah ter replace"""

#data Ca
data.head(275)

#data Thal
data.head(83)

"""Informasi Data"""

p = data.hist(figsize = (20,10))

"""Menampilkan jumlah data jenis kelamin

# Feature-feature Dataset
"""

Jenkel = ['0 : Perempuan','1 : Laki-laki']
sex = data.Sex.value_counts(sort=True)
print (Jenkel)
print (sex)

"""Tampilan jumlah data CP"""

cp =['1: typical angina','2: atypical angina','3: non-anginal pain','4: asymptomatic' ]
cP = data.Cp.value_counts(sort= True)
print (cp)
print (cP)

"""Deskripsi Target/ Num"""

target_names = ['0 : Healthy','1 : Low','2 : Medium','3 : High','4 : Serious']
num = data.Num.value_counts(sort=True)
print (target_names)
print (num)

"""Menampilkan Deskripsi Restecg"""

Rstcg = data.Restecg.value_counts(sort=True)
Restecg = ['0 : normal','1 : having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)', '2 : showing probable or definite left ventricular hypertrophy by Estesâ€™ criteria)']
print(Restecg)
print (Rstcg)

"""Menampilkan Data Fbs"""

a = data.Fbs.value_counts(sort=True)
Fbs = ('0 : False','1 : True')
print ("Fasting Blood Sugar > 120 mg/dl")
print (Fbs)
print(a)

"""Menampilkan Data Jenis Kelamin dengan Grafik"""

sns.countplot(x='Sex', data=data, palette="mako_r")
plt.xlabel("Sex (0 = Perempuan, 1= Laki-laki)")
plt.show()

"""Menampilkan Data Usia dengan Grafik"""

sns.set(rc={'figure.figsize':(25,10)}) 
sns.countplot(data["Age"])

"""Menampilkan Scatter Data Usia, Thalach dan Num yang Dapat Mempengaruhi Cardiovascullar Disease"""

plt.scatter(x=data.Age[data.Num==0], y=data.Thalach[(data.Num==0)], c= "blue")
plt.scatter(x=data.Age[data.Num==1], y=data.Thalach[(data.Num==1)], c= "cyan")
plt.scatter(x=data.Age[data.Num==2], y=data.Thalach[(data.Num==2)], c= "gold")
plt.scatter(x=data.Age[data.Num==3], y=data.Thalach[(data.Num==3)], c= "maroon")
plt.scatter(x=data.Age[data.Num==4], y=data.Thalach[(data.Num==4)], c= "red")
plt.legend(["Healthy", "Low", "Medium","High","Serious"])
plt.xlabel("Age")
plt.ylabel("Maximum Heart Rate")
plt.show()

"""Menampilkan Data Jumlah dari Usia Berdasarkan pada Data Num"""

g = sns.FacetGrid(data, col= "Num")
g.map(plt.hist, "Sex")

"""Penormalan Data Sebelum Pengujian dengan Algoritma"""

data.drop('Ca_imputed_median', axis=1, inplace=True)
data.drop('Thal_imputed_median', axis=1, inplace=True)
data.head()

"""# Penerapan Algoritma KNN"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neighbors import DistanceMetric

sc_X = StandardScaler()
X =  pd.DataFrame(sc_X.fit_transform(data.drop(["Num"],axis = 1)),columns=['Age', 'Sex', 'Cp', 'Trestbps', 'Chol', 'Fbs', 'Restecg', 'Thalach', 'Exang', 'Oldpeak', 'Slope', 'Ca', 'Thal'])
y = data.Num
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=96, stratify=y)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)

"""Mencari Jarak Euclidean"""

#Import knearest neighbors Classifier model
#dist = DistanceMetric.get_metric('euclidean')
#X = data
#jarak = dist.pairwise(X)

"""Menginisialisasi Nilai K = 10"""

#Setup a knn classifier with k neighbors
knn = KNeighborsClassifier(n_neighbors = 10, weights='distance', metric = 'euclidean')
knn.fit(X_train,y_train)
scr = knn.score(X_test,y_test)
y_pred = knn.predict(X_test)
print ("Predictions : \n",y_pred)
print ("Score : ",scr)

plt.figure(figsize=(12,5))
plt.scatter(y_test, y_pred)
plt.xlabel("True Value")
plt.ylabel("predictions")

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# Model Accuracy, how often is the classifier correct?
print("Accuracy :{:.2f}".format(metrics.accuracy_score(y_test, y_pred)))

"""Melakukan Pengujian dengan Nilai Akurasi"""

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))

print(classification_report(y_test, y_pred))

from sklearn.model_selection import cross_val_predict
import matplotlib.pyplot as plt


# cross_val_predict returns an array of the same size as `y` where each entry
# is a prediction obtained by cross validation:
predicted = cross_val_predict(knn, X, y, cv=10)

fig, ax = plt.subplots()
ax.scatter(y, predicted, edgecolors=(0, 0, 0))
ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=1)
ax.set_xlabel('Measured')
ax.set_ylabel('Predicted')
plt.show()

error = []

# Calculating error for K values between 1 and 10
for i in range(1, 11):  
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_train)
    error.append(np.mean(y_pred != y_train))

plt.figure(figsize=(12, 6))  
plt.plot(range(1,11), error, color='green', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)
plt.title('Error Rate Nilai K')  
plt.xlabel('Nilai K')  
plt.ylabel('Error rata-rata')

"""Sumber dari : https://www.kdnuggets.com/2019/07/classifying-heart-disease-using-k-nearest-neighbors.html/2

# Backpropagation
"""

from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

X = data.drop(['Num'], axis = 1)
y = data.Num.values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)

sc = StandardScaler()
sc.fit(X_train)
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.neural_network import MLPClassifier
mlp = MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,
      hidden_layer_sizes=(1024,), learning_rate='constant', learning_rate_init=0.005, max_fun=15000, max_iter=1000, momentum=0.9,
      n_iter_no_change=24, nesterovs_momentum=True, power_t=0.5, random_state= 1, shuffle=True, solver='adam', tol=1e-04,
      validation_fraction=0.01, verbose=False, warm_start=False)
mlp.fit(X_train,y_train)

y_pred = mlp.predict(X_test)
print ('y_test : \n',y_test)
print ('y_train : \n',y_train)
#print ('x_test : \n',X_test)
#print ('x_train : \n',X_train)
print ('Predictions : \n', y_pred)
print("Accuracy :{:.2f}".format(metrics.accuracy_score(y_test, y_pred)))

from sklearn.metrics import classification_report,confusion_matrix
print(confusion_matrix(y_test,y_pred))

print(classification_report(y_test,y_pred))

def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):
    """Create a sample plot for indices of a cross-validation object."""

    # Generate the training/testing visualizations for each CV split
    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):
        # Fill in indices with the training/test groups
        indices = np.array([np.nan] * len(X))
        indices[tt] = 1
        indices[tr] = 0

        # Visualize the results
        ax.scatter(range(len(indices)), [ii + .5] * len(indices),
                   c=indices, marker='_', lw=lw, cmap=cmap_cv,
                   vmin=-.2, vmax=1.2)

    # Plot the data classes and groups at the end
    ax.scatter(range(len(X)), [ii + 1.5] * len(X),
               c=y, marker='_', lw=lw, cmap=cmap_data)

    ax.scatter(range(len(X)), [ii + 2.5] * len(X),
               c=group, marker='_', lw=lw, cmap=cmap_data)

    # Formatting
    yticklabels = list(range(n_splits)) + ['class', 'group']
    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,
           xlabel='Sample index', ylabel="CV iteration",
           ylim=[n_splits+2.2, -.2], xlim=[0, 243])
    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)
    return ax

n_splits = 10
cmap_data = plt.cm.Paired
cmap_cv = plt.cm.coolwarm
fig, ax = plt.subplots(figsize=(10,5))
groups = np.hstack([[ii] * 1 for ii in range(243)])
cv = KFold(n_splits)
plot_cv_indices(cv, X_train, y_train, groups, ax, n_splits)